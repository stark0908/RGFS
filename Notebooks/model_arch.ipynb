{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedf99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c240863",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropBlock2D(nn.Module):\n",
    "    def __init__(self, drop_prob=0.1, block_size=3):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.drop_prob == 0.:\n",
    "            return x\n",
    "        else:\n",
    "            gamma = self._compute_gamma(x)\n",
    "            mask = (torch.rand(x.shape[0], 1, x.shape[2], x.shape[3], device=x.device) < gamma).float()\n",
    "            mask = self._compute_block_mask(mask)\n",
    "            countM = mask.numel()\n",
    "            count_ones = mask.sum()\n",
    "            return mask * x * (countM / count_ones)\n",
    "\n",
    "    def _compute_block_mask(self, mask):\n",
    "        block_mask = nn.functional.max_pool2d(\n",
    "            input=mask,\n",
    "            kernel_size=(self.block_size, self.block_size),\n",
    "            stride=(1, 1),\n",
    "            padding=self.block_size // 2\n",
    "        )\n",
    "        return 1 - block_mask\n",
    "\n",
    "    def _compute_gamma(self, x):\n",
    "        return self.drop_prob / (self.block_size ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, drop_prob=0.3, block_size=3):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "        # Freeze all parameters initially\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Unfreeze parameters of the last block (layer4) for fine-tuning\n",
    "        for param in resnet.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        # Create a sequence of layers, inserting DropBlock after layer3 and layer4.\n",
    "        # This is analogous to the original VGG implementation where DropBlock was\n",
    "        # inserted after major feature extraction/downsampling stages.\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            DropBlock2D(drop_prob=drop_prob, block_size=block_size),\n",
    "            resnet.layer4,\n",
    "            DropBlock2D(drop_prob=drop_prob, block_size=block_size)\n",
    "        )\n",
    "\n",
    "        # The output of ResNet-50's layer4 has 2048 channels.\n",
    "        # The Decoder and embedding head expect 512 channels.\n",
    "        # This bottleneck layer reduces the channel dimension to ensure compatibility.\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(2048, 512, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Ensure the new bottleneck layer is trainable\n",
    "        for param in self.bottleneck.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.bottleneck(x)   # Output shape: [B, 512, 7, 7]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            #formula to calcu;ate dim in convtranspose is used such that always double easier to deal ig\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),  # 7 → 14 (7(in)-1)*2 -2*1(pad) + 3(ker_size) + 1(out_pad)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 14 → 28\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),   # 28 → 56\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),    # 56 → 112\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),    # 112 → 224\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding=1),  # Keep output channels 3 (RGB)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)  # Output: [B, 3, 224, 224]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46ecb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedAutoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.embedding_head = nn.Sequential(\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),             \n",
    "        nn.Linear(512, 256)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, masked_img, mask=None):\n",
    "        latent = self.encoder(masked_img)\n",
    "        recon = self.decoder(latent)\n",
    "        embedding=self.embedding_head(latent)\n",
    "        return recon,embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a939cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "model = MaskedAutoencoder(encoder, decoder).to(device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
